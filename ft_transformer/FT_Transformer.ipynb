{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "6B55J9j87sE_"
      },
      "id": "6B55J9j87sE_"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "afed6d08-5bef-42e4-a1b1-07f406fe5359",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "afed6d08-5bef-42e4-a1b1-07f406fe5359",
        "outputId": "b2bcc67c-4cbe-408c-b241-b2b4b9aa9424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows after cleaning & filtering: 436657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STFIPS  EDUC  EMPLOY  GENDER  LIVARAG  AGE  RACE  ETHNIC  PRIMINC  HLTHINS  \\\n",
              "0       2     4       4       1        2    5     1       4        1        2   \n",
              "1       2     2       4       2        3    2     1       4        4        2   \n",
              "2       2     4       4       2        3    9     2       4        3        4   \n",
              "3       2     3       4       2        3   11     4       4        5        2   \n",
              "4       2     2       4       2        3    5     7       2        5        2   \n",
              "\n",
              "   DIVISION  REGION  SUB1  \n",
              "0         9       4     2  \n",
              "1         9       4     2  \n",
              "2         9       4     2  \n",
              "3         9       4     5  \n",
              "4         9       4     5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad2b77a4-b79c-498f-aed1-05a4738b08b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STFIPS</th>\n",
              "      <th>EDUC</th>\n",
              "      <th>EMPLOY</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>LIVARAG</th>\n",
              "      <th>AGE</th>\n",
              "      <th>RACE</th>\n",
              "      <th>ETHNIC</th>\n",
              "      <th>PRIMINC</th>\n",
              "      <th>HLTHINS</th>\n",
              "      <th>DIVISION</th>\n",
              "      <th>REGION</th>\n",
              "      <th>SUB1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad2b77a4-b79c-498f-aed1-05a4738b08b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad2b77a4-b79c-498f-aed1-05a4738b08b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad2b77a4-b79c-498f-aed1-05a4738b08b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-19cb5739-49cc-43b8-9791-5b3efaa32a08\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19cb5739-49cc-43b8-9791-5b3efaa32a08')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-19cb5739-49cc-43b8-9791-5b3efaa32a08 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# ── Cell 1 ───────────────────────────────────────────────────────────\n",
        "import pandas as pd, numpy as np, torch, random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic, torch.backends.cudnn.benchmark = True, False\n",
        "\n",
        "# ── user dials\n",
        "DATA_PATH = Path(\"tedsa_puf_2020.csv\")\n",
        "SUB1_KEEP = [2, 4, 5, 10]\n",
        "FRACTION  = 1.0\n",
        "\n",
        "KEEP_COLS = [\n",
        "    \"AGE\", \"GENDER\", \"RACE\", \"ETHNIC\", \"EDUC\", \"EMPLOY\",\n",
        "    \"LIVARAG\", \"PRIMINC\", \"STFIPS\", \"REGION\", \"DIVISION\",\n",
        "    \"HLTHINS\", \"SUB1\"\n",
        "]\n",
        "\n",
        "df = pd.read_csv(DATA_PATH, usecols=KEEP_COLS)\n",
        "\n",
        "if 0 < FRACTION < 1:\n",
        "    df = df.sample(frac=FRACTION, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "TARGET = \"SUB1\"\n",
        "feature_cols = [c for c in df.columns if c != TARGET]\n",
        "\n",
        "# 1 · drop rows containing sentinel −9 in any predictor column\n",
        "df = df[~(df[feature_cols] == -9).any(axis=1)].reset_index(drop=True)\n",
        "\n",
        "# 2 · keep only desired SUB1 classes\n",
        "df = df[df[TARGET].isin(SUB1_KEEP)].reset_index(drop=True)\n",
        "\n",
        "# 3 · move SUB1 to the far-right side of the DataFrame\n",
        "df = df[[c for c in df.columns if c != TARGET] + [TARGET]]\n",
        "\n",
        "print(f\"Rows after cleaning & filtering: {len(df)}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fa6e0857-4a87-4ea2-863a-eed645e8c589",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa6e0857-4a87-4ea2-863a-eed645e8c589",
        "outputId": "a99a6ff3-7a47-4e48-f107-7592e315cc0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows : 349325\n",
            "Test  rows : 87332\n",
            "\n",
            "CSV files written: tedsa_train_split.csv, tedsa_test_split.csv\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 2 ───────────────────────────────────────────────────────────\n",
        "TARGET = \"SUB1\"\n",
        "feature_cols = [c for c in df.columns if c != TARGET]\n",
        "\n",
        "# 0 · map each kept SUB1 code to 0…k-1\n",
        "sub1_to_idx = {code: idx for idx, code in enumerate(SUB1_KEEP)}\n",
        "df[\"TARGET_ID\"] = df[TARGET].map(sub1_to_idx).astype(\"int64\")\n",
        "\n",
        "# 1 · label-encode every predictor\n",
        "for col in feature_cols:\n",
        "    df[col] = (\n",
        "        df[col]\n",
        "          .astype(\"category\")\n",
        "          .cat.add_categories(\"UNK\")\n",
        "          .fillna(\"UNK\")          # safeguards genuine NaNs\n",
        "          .cat.codes\n",
        "          .astype(\"int64\")\n",
        "    )\n",
        "\n",
        "# 2 · schema info\n",
        "n_classes = len(SUB1_KEEP)\n",
        "cat_cardinalities = [df[c].nunique() for c in feature_cols]\n",
        "\n",
        "# 3 · stratified train/test split\n",
        "train_df, test_df = train_test_split(\n",
        "    df, stratify=df[\"TARGET_ID\"], test_size=0.20, random_state=SEED\n",
        ")\n",
        "\n",
        "# 4 · numpy tensors for the model\n",
        "X_train_cat = train_df[feature_cols].to_numpy(np.int64)\n",
        "X_test_cat  =  test_df[feature_cols].to_numpy(np.int64)\n",
        "y_train     = train_df[\"TARGET_ID\"].to_numpy(np.int64)\n",
        "y_test      =  test_df[\"TARGET_ID\"].to_numpy(np.int64)\n",
        "\n",
        "# 5 · report sizes and save CSVs\n",
        "print(f\"Train rows : {len(train_df)}\")\n",
        "print(f\"Test  rows : {len(test_df)}\\n\")\n",
        "\n",
        "train_df.to_csv(\"tedsa_train_split.csv\", index=False)\n",
        "test_df.to_csv(\"tedsa_test_split.csv\",  index=False)\n",
        "\n",
        "print(\"CSV files written: tedsa_train_split.csv, tedsa_test_split.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning"
      ],
      "metadata": {
        "id": "fJy8_RV-7wJR"
      },
      "id": "fJy8_RV-7wJR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd13d1f-c148-47a1-b3da-124c41e6411a",
      "metadata": {
        "id": "5cd13d1f-c148-47a1-b3da-124c41e6411a",
        "outputId": "7c2e4bcc-6c0f-4469-a6f4-8c258ad917f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-19 17:29:31,466] A new study created in memory with name: no-name-3703176d-1e8c-4a82-9225-169c521d72c8\n",
            "[I 2025-06-19 18:01:32,868] Trial 0 finished with value: 0.47447323907136835 and parameters: {'d_block': 192, 'n_blocks': 2, 'attention_n_heads': 8, 'attention_dropout': 0.049086378176820225, 'ffn_dropout': 0.3251215549423043, 'residual_dropout': 0.10062536302844134, 'ffn_d_hidden_multiplier': 3.271520661705991, 'lr': 0.00016224821579518352, 'batch_size': 256, 'loss_type': 'focal'}. Best is trial 0 with value: 0.47447323907136835.\n",
            "[I 2025-06-19 20:31:35,646] Trial 1 finished with value: 0.4768343067973525 and parameters: {'d_block': 256, 'n_blocks': 6, 'attention_n_heads': 8, 'attention_dropout': 0.12443808572882027, 'ffn_dropout': 0.19462667261713232, 'residual_dropout': 0.24851363274917035, 'ffn_d_hidden_multiplier': 5.069675871882938, 'lr': 0.0001650455464576478, 'batch_size': 128, 'loss_type': 'focal'}. Best is trial 1 with value: 0.4768343067973525.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best mean-CV accuracy: 0.4768343067973525\n",
            "Best hyper-parameters: {'d_block': 256, 'n_blocks': 6, 'attention_n_heads': 8, 'attention_dropout': 0.12443808572882027, 'ffn_dropout': 0.19462667261713232, 'residual_dropout': 0.24851363274917035, 'ffn_d_hidden_multiplier': 5.069675871882938, 'lr': 0.0001650455464576478, 'batch_size': 128, 'loss_type': 'focal'}\n"
          ]
        }
      ],
      "source": [
        "# Cell 3 ──────────────────────────────────────────────────────────────\n",
        "# Hyper-parameter tuning for FT-Transformer (all-categorical)\n",
        "\n",
        "import torch, optuna, numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from rtdl_revisiting_models import FTTransformer\n",
        "\n",
        "# ── dataset wrapper ─────────────────────────────────────────────────\n",
        "class CatOnlyDataset(Dataset):\n",
        "    def __init__(self, X_cat, y):\n",
        "        self.X_cat = torch.as_tensor(X_cat, dtype=torch.long)\n",
        "        self.y     = torch.as_tensor(y,      dtype=torch.long)\n",
        "    def __len__(self):          return self.y.size(0)\n",
        "    def __getitem__(self, idx): return self.X_cat[idx], self.y[idx]\n",
        "\n",
        "# ── focal loss implementation ───────────────────────────────────────\n",
        "def focal_loss(logits, targets, gamma=2.0, weight=None):\n",
        "    log_probs = F.log_softmax(logits, dim=1)\n",
        "    probs     = torch.exp(log_probs)\n",
        "    tgt_log_p = log_probs[range(len(targets)), targets]\n",
        "    tgt_p     = probs[range(len(targets)), targets]\n",
        "    loss      = -((1.0 - tgt_p) ** gamma) * tgt_log_p\n",
        "    if weight is not None:\n",
        "        loss = loss * weight[targets]\n",
        "    return loss.mean()\n",
        "\n",
        "# ── epoch loop ──────────────────────────────────────────────────────\n",
        "def run_epoch(model, loader, loss_fn, optimizer=None):\n",
        "    train = optimizer is not None\n",
        "    model.train() if train else model.eval()\n",
        "    loss_sum, correct, total = 0.0, 0, 0\n",
        "    for x_cat, y in loader:\n",
        "        x_cat, y = x_cat.to(device), y.to(device)\n",
        "        logits   = model(None, x_cat)\n",
        "        loss     = loss_fn(logits, y)\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        loss_sum += loss.item() * y.size(0)\n",
        "        correct  += (logits.argmax(1) == y).sum().item()\n",
        "        total    += y.size(0)\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "# ── Optuna objective ────────────────────────────────────────────────\n",
        "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_wts  = torch.tensor(\n",
        "    compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train),\n",
        "    dtype=torch.float32, device=device\n",
        ")\n",
        "\n",
        "def objective(trial):\n",
        "    # ── hyper-parameters to search ──────────────────────────────────\n",
        "    d_block          = trial.suggest_categorical(\"d_block\",  [128, 192, 256, 320])\n",
        "    n_blocks         = trial.suggest_int        (\"n_blocks\", 2, 6)\n",
        "    n_heads          = trial.suggest_categorical(\"attention_n_heads\", [4, 8])\n",
        "    attn_dropout     = trial.suggest_float      (\"attention_dropout\", 0.0, 0.4)\n",
        "    ffn_dropout      = trial.suggest_float      (\"ffn_dropout\",       0.0, 0.4)\n",
        "    residual_dropout = trial.suggest_float      (\"residual_dropout\",  0.0, 0.3)\n",
        "    ffn_mult         = trial.suggest_float      (\"ffn_d_hidden_multiplier\", 1.0, 6.0)\n",
        "    lr               = trial.suggest_float      (\"lr\", 1e-4, 1e-3, log=True)\n",
        "    batch_size       = trial.suggest_categorical(\"batch_size\", [128, 256, 512])\n",
        "    loss_type        = trial.suggest_categorical(\"loss_type\", [\"ce\", \"focal\"])\n",
        "\n",
        "    # pick loss function object once per trial\n",
        "    if loss_type == \"ce\":\n",
        "        loss_fn = lambda logits, y: F.cross_entropy(\n",
        "            logits, y, weight=base_wts, label_smoothing=0.1\n",
        "        )\n",
        "    else:  # focal\n",
        "        loss_fn = lambda logits, y: focal_loss(logits, y, gamma=2.0, weight=base_wts)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    fold_accs = []\n",
        "\n",
        "    for tr_idx, va_idx in cv.split(X_train_cat, y_train):\n",
        "        # ── Datasets ────────────────────────────────────────────────\n",
        "        X_tr, y_tr = X_train_cat[tr_idx], y_train[tr_idx]\n",
        "        X_va, y_va = X_train_cat[va_idx], y_train[va_idx]\n",
        "        ds_tr = CatOnlyDataset(X_tr, y_tr)\n",
        "        ds_va = CatOnlyDataset(X_va, y_va)\n",
        "\n",
        "        # balanced sampler for the training fold\n",
        "        class_counts = np.bincount(y_tr)\n",
        "        samp_wts     = 1.0 / class_counts[y_tr]\n",
        "        sampler      = WeightedRandomSampler(\n",
        "            weights=samp_wts, num_samples=len(samp_wts), replacement=True\n",
        "        )\n",
        "\n",
        "        dl_tr = DataLoader(ds_tr, batch_size=batch_size, sampler=sampler)\n",
        "        dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # ── Model ───────────────────────────────────────────────────\n",
        "        model = FTTransformer(\n",
        "            n_cont_features=0,\n",
        "            cat_cardinalities=cat_cardinalities,\n",
        "            d_out=n_classes,\n",
        "            n_blocks=n_blocks,\n",
        "            d_block=d_block,\n",
        "            attention_n_heads=n_heads,\n",
        "            attention_dropout=attn_dropout,\n",
        "            ffn_d_hidden_multiplier=ffn_mult,\n",
        "            ffn_dropout=ffn_dropout,\n",
        "            residual_dropout=residual_dropout,\n",
        "        ).to(device)\n",
        "\n",
        "        # cosine annealing schedule with warm-up\n",
        "        opt = torch.optim.AdamW(model.make_parameter_groups(), lr=lr, weight_decay=1e-2)\n",
        "        sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=20)\n",
        "\n",
        "        best_acc, patience, wait = 0.0, 10, 0\n",
        "        for epoch in range(100):\n",
        "            run_epoch(model, dl_tr, loss_fn, opt)\n",
        "            sched.step()\n",
        "            _, val_acc = run_epoch(model, dl_va, loss_fn)\n",
        "            if val_acc > best_acc:\n",
        "                best_acc, wait = val_acc, 0\n",
        "            else:\n",
        "                wait += 1\n",
        "            if wait >= patience:\n",
        "                break\n",
        "\n",
        "        fold_accs.append(best_acc)\n",
        "\n",
        "    return float(np.mean(fold_accs))\n",
        "\n",
        "# ── run the Optuna study ────────────────────────────────────────────\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=16, timeout=60*60)   # ↑ trials; ↑ timeout\n",
        "\n",
        "print(\"Best mean-CV accuracy:\", study.best_value)\n",
        "print(\"Best hyper-parameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "-90qDiVn7zm4"
      },
      "id": "-90qDiVn7zm4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b24e9b9-bf71-4bd4-82ed-e719f0ebda77",
      "metadata": {
        "id": "3b24e9b9-bf71-4bd4-82ed-e719f0ebda77",
        "outputId": "4af6aefc-fef7-40d7-af57-6a02b536cd87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final training done.\n"
          ]
        }
      ],
      "source": [
        "# Cell 4 ──────────────────────────────────────────────────────────────\n",
        "best = study.best_params\n",
        "loss_fn = (\n",
        "    (lambda l, y: F.cross_entropy(l, y, weight=base_wts, label_smoothing=0.1))\n",
        "    if best[\"loss_type\"] == \"ce\"\n",
        "    else (lambda l, y: focal_loss(l, y, weight=base_wts))\n",
        ")\n",
        "\n",
        "model = FTTransformer(\n",
        "    n_cont_features=0,\n",
        "    cat_cardinalities=cat_cardinalities,\n",
        "    d_out=n_classes,\n",
        "    n_blocks=best[\"n_blocks\"],\n",
        "    d_block=best[\"d_block\"],\n",
        "    attention_n_heads=best[\"attention_n_heads\"],\n",
        "    attention_dropout=best[\"attention_dropout\"],\n",
        "    ffn_d_hidden_multiplier=best[\"ffn_d_hidden_multiplier\"],\n",
        "    ffn_dropout=best[\"ffn_dropout\"],\n",
        "    residual_dropout=best[\"residual_dropout\"],\n",
        ").to(device)\n",
        "\n",
        "opt   = torch.optim.AdamW(model.make_parameter_groups(), lr=best[\"lr\"], weight_decay=1e-2)\n",
        "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=20)\n",
        "\n",
        "# balanced sampler on entire training set\n",
        "counts  = np.bincount(y_train)\n",
        "weights = 1.0 / counts[y_train]\n",
        "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
        "loader_tr = DataLoader(CatOnlyDataset(X_train_cat, y_train),\n",
        "                       batch_size=best[\"batch_size\"], sampler=sampler)\n",
        "\n",
        "for epoch in range(50):\n",
        "    run_epoch(model, loader_tr, loss_fn, opt); sched.step()\n",
        "print(\"Final training done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02662a45-a367-487d-a701-5093703d2359",
      "metadata": {
        "id": "02662a45-a367-487d-a701-5093703d2359"
      },
      "outputs": [],
      "source": [
        "# Cell 5 ──────────────────────────────────────────────────────────────\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, confusion_matrix,\n",
        "    classification_report, f1_score\n",
        ")\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "test_loader = DataLoader(\n",
        "    CatOnlyDataset(X_test_cat, y_test),\n",
        "    batch_size=best[\"batch_size\"], shuffle=False\n",
        ")\n",
        "\n",
        "all_logits, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for x_cat, y in test_loader:\n",
        "        logits = model(None, x_cat.to(device))\n",
        "        all_logits.append(logits.cpu())\n",
        "        all_labels.append(y)\n",
        "logits = torch.cat(all_logits).numpy()\n",
        "y_true = torch.cat(all_labels).numpy()\n",
        "y_pred = logits.argmax(1)\n",
        "\n",
        "# ── Metrics ---------------------------------------------------------\n",
        "acc      = accuracy_score(y_true, y_pred)\n",
        "macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "micro_f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
        "\n",
        "# ROC-AUC (ovo)\n",
        "probs = torch.softmax(torch.tensor(logits), 1).numpy()\n",
        "try:\n",
        "    auc_macro = roc_auc_score(y_true, probs, multi_class=\"ovo\", average=\"macro\")\n",
        "except ValueError:\n",
        "    auc_macro = float(\"nan\")  # happens if a class absent in y_true\n",
        "\n",
        "print(f\"Accuracy      : {acc:.4f}\")\n",
        "print(f\"Macro F1      : {macro_f1:.4f}\")\n",
        "print(f\"Micro F1      : {micro_f1:.4f}\")\n",
        "print(f\"Macro ROC-AUC : {auc_macro:.4f}\\n\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# ── Confusion matrix ------------------------------------------------\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=SUB1_KEEP, yticklabels=SUB1_KEEP)\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "# ── Cell 5 ───────────────────────────────────────────────────────────\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, confusion_matrix,\n",
        "    classification_report, f1_score\n",
        ")\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ── inference ───────────────────────────────────────────────────────\n",
        "model.eval()\n",
        "test_loader = DataLoader(\n",
        "    CatOnlyDataset(X_test_cat, y_test),\n",
        "    batch_size=best[\"batch_size\"],\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "all_logits, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for x_cat, y in test_loader:\n",
        "        logits = model(None, x_cat.to(device))\n",
        "        all_logits.append(logits.cpu())\n",
        "        all_labels.append(y)\n",
        "logits = torch.cat(all_logits).numpy()\n",
        "y_true = torch.cat(all_labels).numpy()\n",
        "y_pred = logits.argmax(1)\n",
        "\n",
        "# ── metrics ---------------------------------------------------------\n",
        "acc      = accuracy_score(y_true, y_pred)\n",
        "macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "micro_f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
        "\n",
        "probs = torch.softmax(torch.tensor(logits), 1).numpy()\n",
        "try:\n",
        "    auc_macro = roc_auc_score(y_true, probs, multi_class=\"ovo\", average=\"macro\")\n",
        "except ValueError:\n",
        "    auc_macro = float(\"nan\")          # occurs if a class absent in y_true\n",
        "\n",
        "print(f\"Accuracy      : {acc:.4f}\")\n",
        "print(f\"Macro F1      : {macro_f1:.4f}\")\n",
        "print(f\"Micro F1      : {micro_f1:.4f}\")\n",
        "print(f\"Macro ROC-AUC : {auc_macro:.4f}\\n\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# ── confusion matrix -----------------------------------------------\n",
        "cm     = confusion_matrix(y_true, y_pred)\n",
        "cm_df  = pd.DataFrame(cm, index=SUB1_KEEP, columns=SUB1_KEEP)\n",
        "\n",
        "plt.figure(figsize=(8, 6))                    # enlarge canvas\n",
        "sns.heatmap(\n",
        "    cm_df,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar=False,\n",
        "    square=True,\n",
        "    linewidths=0.5,\n",
        "    linecolor=\"white\",\n",
        "    annot_kws={\"size\": 14}                    # smaller font if needed\n",
        ")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.yticks(rotation=0)                        # keep y-axis labels horizontal\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8905e85-c18f-4af7-b22b-6bf8d6333dbe",
      "metadata": {
        "id": "f8905e85-c18f-4af7-b22b-6bf8d6333dbe"
      },
      "outputs": [],
      "source": [
        "# Cell 6 ──────────────────────────────────────────────────────────────\n",
        "# Feature importance via permutation on the test set\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ── baseline performance (already computed) ─────────────────────────\n",
        "baseline_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "\n",
        "def perm_importance(model, X_base, y, metric, batch_size):\n",
        "    \"\"\"Return drop in metric for every feature after permutation.\"\"\"\n",
        "    drops = []\n",
        "    X_perm = deepcopy(X_base)\n",
        "\n",
        "    for col_idx in range(X_base.shape[1]):\n",
        "        # shuffle a single column\n",
        "        np.random.shuffle(X_perm[:, col_idx])\n",
        "\n",
        "        # re-evaluate\n",
        "        ds = CatOnlyDataset(X_perm, y)\n",
        "        dl = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        all_logits = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in dl:\n",
        "                logits = model(None, xb.to(device))\n",
        "                all_logits.append(logits.cpu())\n",
        "        logits = torch.cat(all_logits).numpy()\n",
        "        y_hat = logits.argmax(1)\n",
        "        score = metric(y, y_hat)\n",
        "\n",
        "        drops.append(baseline_f1 - score)\n",
        "\n",
        "        # restore the column for the next round\n",
        "        X_perm[:, col_idx] = X_base[:, col_idx]\n",
        "\n",
        "    return np.array(drops)\n",
        "\n",
        "drops = perm_importance(model, X_test_cat.copy(), y_test,\n",
        "                        lambda y, yhat: f1_score(y, yhat, average=\"macro\"),\n",
        "                        best[\"batch_size\"])\n",
        "\n",
        "# ── tidy & plot ─────────────────────────────────────────────────────\n",
        "imp_df = pd.DataFrame({\n",
        "    \"feature\": feature_cols,\n",
        "    \"drop_in_macro_f1\": drops\n",
        "}).sort_values(\"drop_in_macro_f1\", ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(imp_df[\"feature\"], imp_df[\"drop_in_macro_f1\"])\n",
        "plt.gca().invert_yaxis()\n",
        "plt.xlabel(\"Macro-F1 drop when permuted (higher = more important)\")\n",
        "plt.title(\"Permutation feature importance — FT-Transformer\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "imp_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ],
      "metadata": {
        "id": "SyHWoVhY74Ta"
      },
      "id": "SyHWoVhY74Ta"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab69de2-0e9a-418e-84a2-5b6516f2b458",
      "metadata": {
        "id": "4ab69de2-0e9a-418e-84a2-5b6516f2b458"
      },
      "outputs": [],
      "source": [
        "# ── Cell 7 ───────────────────────────────────────────────────────────\n",
        "# Save the trained FT-Transformer and its metadata\n",
        "\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# directory + filename\n",
        "save_dir  = Path(\"checkpoints\")\n",
        "save_dir.mkdir(exist_ok=True)\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "ckpt_path = save_dir / f\"ft_transformer_{timestamp}.pt\"\n",
        "\n",
        "# model weights + essential metadata\n",
        "checkpoint = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"cat_cardinalities\": cat_cardinalities,\n",
        "    \"sub1_to_idx\": sub1_to_idx,          # label mapping\n",
        "    \"best_params\": best,                 # hyper-parameters from Optuna\n",
        "    \"seed\": SEED,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, ckpt_path)\n",
        "print(f\"Model saved to: {ckpt_path.resolve()}\")\n",
        "\n",
        "# (optional) persist the label mapping as a JSON side-car\n",
        "json_path = ckpt_path.with_suffix(\".json\")\n",
        "with open(json_path, \"w\") as fp:\n",
        "    json.dump({\"sub1_to_idx\": sub1_to_idx}, fp, indent=2)\n",
        "print(f\"Label map saved to: {json_path.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61b1967-89ed-4725-9882-754c1abee6ef",
      "metadata": {
        "id": "b61b1967-89ed-4725-9882-754c1abee6ef"
      },
      "outputs": [],
      "source": [
        "# load model from file code\n",
        "\n",
        "# import torch\n",
        "# from rtdl_revisiting_models import FTTransformer\n",
        "\n",
        "# ckpt = torch.load(\"checkpoints/ft_transformer_YYYYMMDD_HHMMSS.pt\", map_location=\"cpu\")\n",
        "\n",
        "# model = FTTransformer(\n",
        "#     n_cont_features=0,\n",
        "#     cat_cardinalities=ckpt[\"cat_cardinalities\"],\n",
        "#     d_out=len(ckpt[\"sub1_to_idx\"]),\n",
        "#     **{k: v for k, v in ckpt[\"best_params\"].items()\n",
        "#        if k in (\"n_blocks\", \"d_block\", \"attention_n_heads\",\n",
        "#                 \"attention_dropout\", \"ffn_d_hidden_multiplier\",\n",
        "#                 \"ffn_dropout\", \"residual_dropout\")}\n",
        "# )\n",
        "# model.load_state_dict(ckpt[\"model_state\"])\n",
        "# model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "187940d6-33a6-4552-8d61-7633b616c232",
      "metadata": {
        "id": "187940d6-33a6-4552-8d61-7633b616c232"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0444913-3740-4909-9389-22bb2bfe72f3",
      "metadata": {
        "id": "f0444913-3740-4909-9389-22bb2bfe72f3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIfkEXfq712L"
      },
      "outputs": [],
      "source": [
        "# === Imports ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna  # Import Optuna\n",
        "\n",
        "# === Load preprocessed data ===\n",
        "file_path = 'modified_tedsa_data_clean.csv'\n",
        "teds_a_data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "categorical_features = [col for col in teds_a_data.columns if col != 'SUB1']\n",
        "\n",
        "# === Prepare features and target ===\n",
        "X = teds_a_data.drop(columns=['SUB1'])\n",
        "y = teds_a_data['SUB1']\n",
        "\n",
        "# === Train/Val/Test split ===\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data Split ---\")\n",
        "print(f\"Total samples:      {len(X)}\")\n",
        "print(f\"Training set size:  {len(X_train)} ({len(X_train)/len(X):.0%})\")\n",
        "print(f\"Validation set size:{len(X_val)} ({len(X_val)/len(X):.0%})\")\n",
        "print(f\"Test set size:      {len(X_test)} ({len(X_test)/len(X):.0%})\")\n",
        "print(\"--------------------\\n\")\n",
        "\n",
        "\n",
        "# === OPTUNA OBJECTIVE ===\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multiclass',\n",
        "        'num_class': len(np.unique(y)),\n",
        "        'boosting_type': 'gbdt',\n",
        "        'random_state': 42,\n",
        "        'n_estimators': 1000,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
        "    }\n",
        "\n",
        "    model = LGBMClassifier(**params)\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric='multi_logloss',\n",
        "        categorical_feature=categorical_features,\n",
        "        callbacks=[early_stopping(stopping_rounds=50, verbose=False)],\n",
        "    )\n",
        "\n",
        "    preds = model.predict(X_val)\n",
        "    score = balanced_accuracy_score(y_val, preds)\n",
        "    return score\n",
        "\n",
        "\n",
        "# === OPTUNA STUDY ===\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "print(\"Best trial:\")\n",
        "best_trial = study.best_trial\n",
        "print(\"  Value: \", best_trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# === FINAL MODEL TRAINING ===\n",
        "print(\"\\n--- Training final model with best parameters on combined train+validation data ---\")\n",
        "final_params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(np.unique(y)),\n",
        "    'boosting_type': 'gbdt',\n",
        "    'random_state': 42,\n",
        "    **best_trial.params,\n",
        "}\n",
        "\n",
        "final_model = LGBMClassifier(**final_params, n_estimators=2000)\n",
        "final_model.fit(\n",
        "    X_train_val,\n",
        "    y_train_val,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    categorical_feature=categorical_features,\n",
        "    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=100)],\n",
        ")\n",
        "\n",
        "# === EVALUATION ON TEST SET ===\n",
        "print(\"\\n--- Final Evaluation on the Test Set ---\")\n",
        "y_pred_classes = final_model.predict(X_test)\n",
        "macro_f1 = f1_score(y_test, y_pred_classes, average='macro')\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred_classes)\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
        "print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes))  # You can add target names if needed\n",
        "\n",
        "# === CONFUSION MATRIX ===\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix on Test Set (After Tuning)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# === FEATURE IMPORTANCE ===\n",
        "importances = final_model.booster_.feature_importance(importance_type='gain')\n",
        "importance_df = pd.DataFrame(\n",
        "    {'Feature': X.columns, 'Importance': importances / np.sum(importances)}\n",
        ").sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title('Feature Importance (Final Model)')\n",
        "plt.xlabel('Importance (Gain)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ]
    }
  ]
}
# Project Goal

This project aims to predict the primary substance of use for individuals at admission to treatment facilities, utilizing the TEDS-A 2020 (Treatment Episode Data Set - Admissions) Public Use File. The primary objective is to evaluate and compare the performance of various machine learning architectures on this task, focusing on a methodology that uses core socio-economic and demographic indicators to predict the most prevalent substance use categories. The project emphasizes methodological rigor and explores the inherent predictability of substance use type based on the selected features.

## Dataset

* **Source:** TEDS-A 2020 Public Use File (`tedsa_puf_2020.csv`)
* **Preprocessing Summary:**

  1. **Feature Selection:** 12 core socio-economic and demographic features (`AGE`, `GENDER`, `RACE`, `ETHNIC`, `EDUC`, `EMPLOY`, `LIVARAG`, `PRIMINC`, `STFIPS`, `REGION`, `DIVISION`, `HLTHINS`) were selected as predictors. The target variable is `SUB1` (primary substance).
  2. **Missing Value Handling:** Rows containing the code `-9` (indicating missing, unknown, or invalid) in any of the 12 features or `SUB1` were entirely removed.
  3. **Target Variable Filtering:** Original `SUB1` categories constituting less than 9% of the cleaned dataset were removed, resulting in 4 final primary substance categories for prediction: Alcohol (original code 2), Marijuana/hashish (4), Heroin (5), and Methamphetamine/speed (10).
  4. **Final Dataset Size:** 436,657 records.
* **Data File Location:** The raw data CSV (`tedsa_puf_2020.csv`) should be placed in the `data/` directory at the root of this project.

## Project Structure

```
TEDS_Substance_Prediction/
├── data/
│   └── tedsa_puf_2020.csv           # Raw data file (place here)
├── src/                             # Source code
│   ├── __init__.py
│   ├── data_preprocessing.py       # Data loading, cleaning, filtering, encoding, splitting
│   └── modeling/                   # Model-specific training, tuning, and evaluation logic
│       ├── __init__.py
│       ├── classical_models.py     # Logistic Regression, Random Forest
│       ├── lightgbm_model.py
│       ├── basic_nn_models.py      # For MLP, EE-NN (using EmbeddingNN)
│       ├── tabnet_model.py
│       ├── ft_transformer_model.py
│       └── deepfm_model.py
├── main.py                         # Main script to run experiments
├── requirements.txt                # Python package dependencies
├── README.md                       # This file
```

## Setup Instructions

1. **Clone the Repository:**

   ```bash
   git clone <your_repository_url>
   cd TEDS_Substance_Prediction
   ```

2. **Create a Virtual Environment (Recommended):**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install Dependencies:**
   Ensure you have Python 3.x installed. Then, install the required packages:

   ```bash
   pip install -r requirements.txt
   ```

4. **Place Data File:**
   Download the `tedsa_puf_2020.csv` file and place it inside the `data/` directory.

## How to Run Experiments

The main script to run the experiments is `main.py`.

1. **Configure Experiments (in `main.py`):**

   * Open `main.py`.
   * At the top, you can set boolean flags in the `RUN_CONFIG` dictionary to `True` or `False` to control which models are trained and evaluated (e.g., `RUN_CONFIG["LightGBM"]["run"] = True`).
   * You can also control whether hyperparameter tuning is performed for each model by setting the respective `"tune"` flag (e.g., `RUN_CONFIG["LightGBM"]["tune"] = True`).
   * Other global configurations like `SEED` and `CSV_FILE_PATH` are also set at the top of `main.py`.

2. **Execute the Main Script:**
   Run the following command from the root directory of the project (`TEDS_Substance_Prediction/`):

   ```bash
   python main.py
   ```

3. **Outputs:**

   * Console output will show the progress of data preprocessing, model training, tuning (if enabled), and evaluation metrics (including classification reports and paths to saved plots/models if implemented within model scripts).
   * Plots (confusion matrices, feature importances, if generated by model scripts) may be displayed or saved to locations specified within those scripts.
   * Trained model objects may be saved by model scripts to locations specified within those scripts.
   * A summary CSV of all model metrics can be optionally created by `main.py` if desired.

## Models Implemented

The following machine learning models were implemented and compared:

* Logistic Regression
* Random Forest
* LightGBM
* Entity Embedding Neural Network (EE-NN)
* TabNet
* FT-Transformer
* DeepFM

Each model was trained on the same preprocessed dataset, which uses 12 socio-economic features to predict 4 primary substance categories. Encoding was performed using LabelEncoders for all features. Class balancing strategies (e.g., SMOTE for DeepFM) were applied as detailed during model development.

## Key Methodological Points

* **Target Variable:** Original `SUB1` filtered to the 4 most prevalent categories (Alcohol, Marijuana/hashish, Heroin, Methamphetamine/speed) based on a 9% frequency threshold after initial cleaning.
* **Features:** 12 core socio-economic and demographic variables.
* **Encoding:** All features and the target variable were LabelEncoded.
* **Evaluation Metric:** Primary focus on Macro F1-score due to potential class imbalance, with Balanced Accuracy and overall Accuracy also reported.

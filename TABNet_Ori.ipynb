{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFJTizlJ61Fj"
      },
      "outputs": [],
      "source": [
        "# â”€â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.utils import resample\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import torch\n",
        "\n",
        "# â”€â”€â”€ Reproducibility â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# â”€â”€â”€ Load + Preprocess Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "df_full = pd.read_csv(\"modified_tedsa_data_clean.csv\")\n",
        "df_full = df_full.sample(n=50000, random_state=42)\n",
        "print(df_full.head())\n",
        "df, _ = train_test_split(df_full, stratify=df_full[\"SUB1\"], random_state=42)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_raw = label_encoder.fit_transform(df[\"SUB1\"])\n",
        "X_raw = df.drop(columns=[\"SUB1\"])\n",
        "cat_cols = X_raw.columns.tolist()\n",
        "cat_maps = {col: {val: i for i, val in enumerate(X_raw[col].unique())} for col in cat_cols}\n",
        "X_encoded = X_raw.apply(lambda col: col.map(cat_maps[col.name]))\n",
        "\n",
        "# â”€â”€â”€ Split Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X_encoded, y_raw, test_size=0.2, stratify=y_raw, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, stratify=y_temp, random_state=42)\n",
        "# 0.125 * 0.8 = 0.10 of original data, so 70/10/20 split overall\n",
        "\n",
        "# â”€â”€â”€ Oversample Training Set Only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def manual_oversample(X, y):\n",
        "    df_bal = pd.concat([X.reset_index(drop=True), pd.Series(y, name=\"label\")], axis=1)\n",
        "    max_count = df_bal[\"label\"].value_counts().max()\n",
        "    df_os = pd.concat([\n",
        "        resample(df_bal[df_bal[\"label\"] == lbl], replace=True, n_samples=max_count, random_state=42)\n",
        "        for lbl in df_bal[\"label\"].unique()\n",
        "    ])\n",
        "    return df_os.drop(columns=\"label\"), df_os[\"label\"]\n",
        "\n",
        "X_train_os, y_train_os = manual_oversample(X_train, y_train)\n",
        "\n",
        "# â”€â”€â”€ Prepare for TabNet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "X_train_np, y_train_np = X_train_os.values, y_train_os.values\n",
        "X_val_np = X_val.values\n",
        "y_val_np = y_val\n",
        "\n",
        "X_test_np = X_test.values\n",
        "y_test_np = y_test\n",
        "\n",
        "\n",
        "cat_idxs = list(range(X_train_np.shape[1]))\n",
        "cat_dims = [len(cat_maps[col]) for col in cat_cols]\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# â”€â”€â”€ Hyperparameter Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "search_space = [\n",
        "    {\"n_d\": d, \"n_a\": a, \"lr\": lr, \"gamma\": g}\n",
        "    for d in [32, 64]\n",
        "    for a in [32, 64]\n",
        "    for lr in [1e-3, 5e-4]\n",
        "    for g in [1.0, 2.0]\n",
        "]\n",
        "random.shuffle(search_space)\n",
        "\n",
        "best_macro_f1 = -1\n",
        "best_model, best_preds, best_true, best_config = None, None, None, None\n",
        "\n",
        "for i, params in enumerate(search_space[:10]):\n",
        "    print(f\"\\nğŸ” Trial {i+1}: {params}\")\n",
        "    model = TabNetClassifier(\n",
        "        n_d=params[\"n_d\"], n_a=params[\"n_a\"], gamma=params[\"gamma\"],\n",
        "        n_steps=5, verbose=0,\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params=dict(lr=params[\"lr\"]),\n",
        "        cat_idxs=cat_idxs, cat_dims=cat_dims, cat_emb_dim=1,\n",
        "        device_name=device\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train=X_train_np, y_train=y_train_np,\n",
        "        eval_set=[(X_val_np, y_val_np)],\n",
        "        eval_name=[\"val\"], eval_metric=[\"balanced_accuracy\"],\n",
        "        max_epochs=100, patience=10, batch_size=64, virtual_batch_size=32\n",
        "    )\n",
        "    preds = model.predict(X_test_np)\n",
        "    macro_f1 = f1_score(y_test_np, preds, average=\"macro\")\n",
        "    print(f\"ğŸ¯ Macro F1: {macro_f1:.4f}\")\n",
        "    if macro_f1 > best_macro_f1:\n",
        "        best_macro_f1 = macro_f1\n",
        "        best_model = model\n",
        "        best_preds = preds\n",
        "        best_true = y_test_np\n",
        "        best_config = params\n",
        "\n",
        "# â”€â”€â”€ Final Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "y_true_labels = label_encoder.inverse_transform(best_true)\n",
        "y_pred_labels = label_encoder.inverse_transform(best_preds)\n",
        "\n",
        "print(\"\\nâœ… Best Hyperparameters:\", best_config)\n",
        "print(f\"ğŸ† Best Macro F1 Score: {best_macro_f1:.4f}\")\n",
        "print(\"\\nğŸ“‹ Final Classification Report:\\n\", classification_report(y_true_labels, y_pred_labels, zero_division=0))\n",
        "print(f\"ğŸ¯ Final Accuracy: {accuracy_score(y_true_labels, y_pred_labels):.4f}\")\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_true_labels, y_pred_labels, xticks_rotation=45, cmap='Blues')\n",
        "plt.title(\"Final Confusion Matrix - TabNet\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}